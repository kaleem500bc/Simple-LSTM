{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO50uw3yErJ2znv0tBMZZj8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaleem500bc/Simple-LSTM/blob/master/Simple_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hiRYfyNse10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torch import nn\n",
        "import random\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from threading import Thread\n",
        "import threading"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6r52rI6jD8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset\n",
        "dataFile = open(\"/content/anna.txt\")\n",
        "\n",
        "data = dataFile.read()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljYvC_o8eyX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Distinct vocabulary in the dataset\n",
        "vocab = set(data)\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "int2char = dict(enumerate(vocab))\n",
        "\n",
        "char2int = dict(zip(int2char.values(),int2char.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjZcEHYePALJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encode our training dataset for input to the NN\n",
        "encoded_text = [char2int[i] for i in data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAqU-3VKPy6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(encodedText,batchSize,seqLen):\n",
        "  #Each batch has this size\n",
        "  totalBatchLen = batchSize*seqLen\n",
        "\n",
        "  #input batches: Dimension (Number of batches, batch size, sequence length)\n",
        "  xtotalLen = encodedText.shape[0]\n",
        "  xnumBatches = xtotalLen//totalBatchLen\n",
        "  xlength = xnumBatches*totalBatchLen\n",
        "  xencoded = encodedText[:xlength]\n",
        "  xencoded = xencoded.view(xnumBatches,batchSize,seqLen)\n",
        "\n",
        "  #Label\n",
        "  ytotalLen = encodedText.shape[0]-1\n",
        "  ynumBatches = ytotalLen // totalBatchLen\n",
        "  ylength = ynumBatches*totalBatchLen\n",
        "  yencoded = encodedText[1:ylength+1]\n",
        "  yencoded = yencoded.view(ynumBatches,batchSize,seqLen)\n",
        "\n",
        "  return xencoded,yencoded\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzK-65sXzC0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchSize = 128\n",
        "seqLen = 100\n",
        "x,y = get_batches(torch.tensor(encoded_text,dtype=torch.float),batchSize,seqLen)\n",
        "x.requires_grad = True\n",
        "y.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww2eYzOt94h3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a36895e4-65b1-4dd7-e575-81ef56d09223"
      },
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([155, 128, 100])\n",
            "torch.Size([155, 128, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6LVgCUDblPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#encode each letter into one hot encoding for multiclass classification for better result\n",
        "#In our case we have vocab_size number of classes as each letter is used as a separate class.\n",
        "def one_hot(x, labels):\n",
        "  one_hot = torch.zeros(np.multiply(*x.shape),labels,dtype=torch.float)\n",
        "  one_hot[torch.arange(one_hot.shape[0]),x.flatten().long()] = 1\n",
        "  return one_hot.view((*x.shape,labels))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhhdTdFp-HFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "422c2926-0f1e-4792-8ee2-20b8cfba444e"
      },
      "source": [
        "class lstmM(nn.Module):\n",
        "  def __init__(self,vocab_size,bidirection=0):\n",
        "    super().__init__()\n",
        "    self.hidden = 512\n",
        "    self.numlayers = 2\n",
        "    self.bdr = bidirection+1\n",
        "    # self.embd = nn.Embedding(vocab_size,10)\n",
        "    self.lstm = nn.LSTM(vocab_size,self.hidden,num_layers=self.numlayers,dropout=0.5,bidirectional=False,batch_first=True)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.f = nn.Linear(self.hidden*self.bdr,vocab_size)\n",
        "\n",
        "  def forward(self,x,prevH):\n",
        "    # x = self.embd(x)\n",
        "    x,(h,c) = self.lstm(x,prevH)\n",
        "    x = self.dropout(x)\n",
        "    x = x.view(-1, self.hidden*self.bdr)\n",
        "    x = self.f(x)\n",
        "    \n",
        "    return x,(h,c)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    param = self.parameters()\n",
        "    p = next(param)\n",
        "    weight = p.data\n",
        "        \n",
        "    hidden = (weight.new(self.numlayers*self.bdr, batch_size, self.hidden).zero_().cuda(),\n",
        "                  weight.new(self.numlayers*self.bdr, batch_size, self.hidden).zero_().cuda())\n",
        "        \n",
        "    return hidden\n",
        "\n",
        "\n",
        "model = lstmM(vocab_size)\n",
        "\n",
        "model.to(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstmM(\n",
              "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (f): Linear(in_features=512, out_features=83, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnS62w-fjFju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(model.parameters(),lr = 0.01)\n",
        "lossHist = []\n",
        "\n",
        "\n",
        "#Run training in background\n",
        "class Train(Thread):\n",
        "  def __init__(self,x,y,epoch):\n",
        "    Thread.__init__(self)\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.epoch = epoch\n",
        "\n",
        "  def run(self):\n",
        "    # global lossHist,x,y\n",
        "    # epoch = 10\n",
        "    epoch = self.epoch\n",
        "    x = self.x\n",
        "    y = self.y\n",
        "    model.train()\n",
        "    for e in range(epoch):\n",
        "      h = model.init_hidden(128)\n",
        "      tloss = 0\n",
        "\n",
        "      i = 0\n",
        "      for batch,target in zip(x,y):\n",
        "        batch = batch.to(\"cuda\")\n",
        "        batch = one_hot(batch,vocab_size).to(\"cuda\")\n",
        "        target = target.to(\"cuda\")\n",
        "        output,(h,c) = model(batch,h)\n",
        "        h = (h.detach(),c.detach())\n",
        "      \n",
        "        optim.zero_grad()\n",
        "\n",
        "        loss = criterion(output,target.view(128*100).long())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "        optim.step()\n",
        "        \n",
        "        tloss = tloss+loss.item()\n",
        "        \n",
        "      lossHist.append(tloss)\n",
        "      print(tloss)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfyaZ7GVc7gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 10\n",
        "\n",
        "#create thread and run\n",
        "training = Train(x,y,epoch)\n",
        "training.name = \"training\"\n",
        "training.start()\n",
        "#check whether our thread is running\n",
        "for thread in threading.enumerate():\n",
        "  print(thread.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Ldfmg1Hchv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#waiting for the main thread\n",
        "training.join()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVhHlohi6ipq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "bc38b826-fd4f-425d-80a1-e0e46db6c3e0"
      },
      "source": [
        "#plot the loss over epoch\n",
        "plt.plot(lossHist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd05a0c8c18>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GovKwg10VhnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def predict(char, h=None, top_k=None):\n",
        "  x=torch.tensor([[char2int[char]]])\n",
        "  x=one_hot(x,vocab_size)\n",
        "  x = x.cuda()\n",
        "  h = tuple([each.data for each in h])\n",
        "  out, h = model(x, h)\n",
        "  p=F.softmax(out, dim=1).data\n",
        "  \n",
        "  p = p.cpu()\n",
        "  if top_k is None:\n",
        "    top_ch = np.arange(vocab_size)\n",
        "  else:\n",
        "    p, top_ch = p.topk(top_k)\n",
        "    top_ch = top_ch.numpy().squeeze()\n",
        "  p= p.numpy().squeeze()\n",
        "  char = np.random.choice(top_ch, p=p/p.sum())\n",
        "  return int2char[char], h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvOrvMcuCvHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(size, prime = 'I am goi', top_k = None):\n",
        "  \n",
        "  model.cuda()\n",
        "  model.eval()\n",
        "  \n",
        "  chars = [ch for ch in prime]\n",
        "  h = model.init_hidden(1)\n",
        "\n",
        "  for ch in prime:\n",
        "    char, h= predict(ch, h, top_k=top_k)\n",
        "  chars.append(char)\n",
        "\n",
        "  for ii in range(size):\n",
        "    char, h = predict(chars[-1], h, top_k=top_k)\n",
        "    chars.append(char)\n",
        "  return ''.join(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJi-ds7VVwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "820d83ce-fa2f-4d8e-ee3a-47ba9bf60b44"
      },
      "source": [
        "print(sample(1000,prime=\"I am goin\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am going\n",
            "to\n",
            "the same thing,\n",
            "and you know I knot him but significanations that uptly that the officer, and been like its\n",
            "second pain weary hating any window, and had\n",
            "seeing the due with his wife.\n",
            "\n",
            "Swe will understand thoogse do they? How are you an one\n",
            "to the\n",
            "teach whole note, thiugh he refund for, Who did\n",
            "not do cold, cleft he dropped on the mind,\n",
            "country with his influence\n",
            "cold mounte stack of patain is\n",
            "kinchantous after the sire of which\n",
            "except his hands who was trying\n",
            "merely tears with it is!\" he said, strusking himself, and he advised ever digination\n",
            "with their blook to place by which hame. Anna answered, and ask without the urmmenty in what Snoped not help their\n",
            "passadence then it was Alexey Alexandrovitch, responded from the box to snot sent to be going out when the horse drave stopped over the group by these day, with him. Without any bebuskys and speaking and trousering crowd and thinking of all, and been over.\n",
            "\n",
            "\"Oh, roomek minute to yevcontant\n",
            "Grisha out of everything for myself that.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptY7wrkc7QAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}